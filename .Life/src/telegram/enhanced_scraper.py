#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ –£–õ–£–ß–®–ï–ù–ù–´–ô TELEGRAM SCRAPER 

–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
‚úÖ –ü—Ä–æ—Å–º–æ—Ç—Ä—ã - 100% —Ä–∞–±–æ—Ç–∞–µ—Ç
‚ùì –õ–∞–π–∫–∏/—Ä–µ–∞–∫—Ü–∏–∏ - –∏—â–µ–º 
‚ùì –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ - –∏—â–µ–º
üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—É–º–º–∞ engagement
"""

import requests
import os
from bs4 import BeautifulSoup
import re
import json
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

class TelegramEnhancedScraper:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä —Å –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π"""
    
    def __init__(self, channel="rawmid"):
        self.channel = channel.replace("@", "")
        self.bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
        }
    
    def get_channel_info_bot_api(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ —á–µ—Ä–µ–∑ Bot API"""
        
        if not self.bot_token:
            return {"error": "No Bot Token"}
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ
            chat_info_url = f"https://api.telegram.org/bot{self.bot_token}/getChat"
            chat_response = requests.get(chat_info_url, params={'chat_id': f'@{self.channel}'}, timeout=10)
            
            if chat_response.status_code == 200:
                chat_data = chat_response.json()
                if chat_data.get('ok'):
                    chat_info = chat_data['result']
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
                    count_url = f"https://api.telegram.org/bot{self.bot_token}/getChatMemberCount"
                    count_response = requests.get(count_url, params={'chat_id': f'@{self.channel}'}, timeout=10)
                    
                    subscribers = 0
                    if count_response.status_code == 200:
                        count_data = count_response.json()
                        if count_data.get('ok'):
                            subscribers = count_data['result']
                    
                    return {
                        'id': chat_info.get('id', ''),
                        'title': chat_info.get('title', ''),
                        'username': chat_info.get('username', ''),
                        'description': chat_info.get('description', ''),
                        'subscribers': subscribers,
                        'type': chat_info.get('type', '')
                    }
            
            return {"error": f"Bot API error: {chat_response.status_code}"}
            
        except Exception as e:
            return {"error": f"Exception: {e}"}
    
    def extract_posts_with_all_metrics(self):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Å—Ç—ã —Å–æ –≤—Å–µ–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        
        print(f"üìä –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ü–û–õ–ù–´–• –ú–ï–¢–†–ò–ö –ò–ó @{self.channel}")
        print("=" * 60)
        
        url = f"https://t.me/s/{self.channel}"
        
        try:
            response = requests.get(url, headers=self.headers, timeout=15)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                posts_elements = soup.find_all('div', class_='tgme_widget_message')
                
                print(f"üìù –ù–∞–π–¥–µ–Ω–æ –ø–æ—Å—Ç–æ–≤: {len(posts_elements)}")
                
                posts_data = []
                
                for i, post_elem in enumerate(posts_elements, 1):
                    post_metrics = self.extract_comprehensive_post_metrics(post_elem, i)
                    if post_metrics:
                        posts_data.append(post_metrics)
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                self.analyze_metrics_availability(posts_data)
                
                return posts_data
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return []
    
    def extract_comprehensive_post_metrics(self, post_elem, post_num):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ø–æ—Å—Ç–∞"""
        
        try:
            metrics = {
                'post_num': post_num,
                'id': '',
                'text_preview': '',
                'date': '',
                'views': 0,
                'likes': 0,
                'comments': 0,
                'reposts': 0,
                'total_engagement': 0,
                'url': '',
                'media_type': 'text'
            }
            
            # ID –ø–æ—Å—Ç–∞ –∏ URL
            post_link = post_elem.get('data-post', '')
            if post_link:
                metrics['id'] = post_link.split('/')[-1]
                metrics['url'] = f"https://t.me/{post_link}"
            else:
                metrics['id'] = f"post_{post_num}"
            
            # –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ (–ø—Ä–µ–≤—å—é)
            text_elem = post_elem.find('div', class_='tgme_widget_message_text')
            if text_elem:
                text_content = text_elem.get_text(strip=True)
                metrics['text_preview'] = text_content[:100] + "..." if len(text_content) > 100 else text_content
            
            # –î–∞—Ç–∞
            date_elem = post_elem.find('time', class_='datetime')
            if date_elem:
                datetime_attr = date_elem.get('datetime', '')
                if datetime_attr:
                    try:
                        date_obj = datetime.fromisoformat(datetime_attr.replace('Z', '+00:00'))
                        metrics['date'] = date_obj.strftime('%Y-%m-%d %H:%M')
                    except:
                        metrics['date'] = date_elem.text.strip()
            
            # –¢–∏–ø –º–µ–¥–∏–∞
            if post_elem.find('video'):
                metrics['media_type'] = 'video'
            elif post_elem.find('img') or post_elem.find('i', class_='tgme_widget_message_photo_wrap'):
                metrics['media_type'] = 'photo'
            elif post_elem.find('audio'):
                metrics['media_type'] = 'audio'
            
            # –ü–†–û–°–ú–û–¢–†–´ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ—á–Ω–æ)
            views_elem = post_elem.find('span', class_='tgme_widget_message_views')
            if views_elem:
                views_text = views_elem.text.strip()
                metrics['views'] = self.convert_count_to_number(views_text)
            
            # –õ–ê–ô–ö–ò/–†–ï–ê–ö–¶–ò–ò (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ)
            metrics['likes'] = self.try_extract_likes(post_elem)
            
            # –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ò (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ)
            metrics['comments'] = self.try_extract_comments(post_elem)
            
            # –†–ï–ü–û–°–¢–´ (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ)
            metrics['reposts'] = self.try_extract_reposts(post_elem)
            
            # –û–±—â–∏–π engagement (–ª–∞–π–∫–∏ + –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏)
            metrics['total_engagement'] = metrics['likes'] + metrics['comments']
            
            return metrics
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞ {post_num}: {e}")
            return None
    
    def try_extract_likes(self, post_elem):
        """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –ª–∞–π–∫–∏ –≤—Å–µ–º–∏ –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ä–µ–∞–∫—Ü–∏–π
        possible_like_selectors = [
            '.tgme_widget_message_reactions',
            '.tgme_widget_message_reaction',
            '[class*="reaction"]',
            '[class*="like"]',
            '[class*="heart"]',
            'span[title*="‚ù§"]',
            'span[title*="üëç"]',
            '.message_reactions',
            '.post_reactions'
        ]
        
        for selector in possible_like_selectors:
            elements = post_elem.select(selector)
            for elem in elements:
                text = elem.get_text(strip=True)
                if text and re.search(r'\d', text):
                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —á–∏—Å–ª–æ –≤ —ç–ª–µ–º–µ–Ω—Ç–µ —Å —Ä–µ–∞–∫—Ü–∏—è–º–∏
                    return self.convert_count_to_number(text)
        
        # Telegram –æ–±—ã—á–Ω–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–∞–π–∫–∏ –≤ –ø—É–±–ª–∏—á–Ω–æ–º –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
        # –±–µ–∑ –∞–¥–º–∏–Ω –¥–æ—Å—Ç—É–ø–∞, –ø–æ—ç—Ç–æ–º—É —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –±—É–¥–µ—Ç 0
        return 0
    
    def try_extract_comments(self, post_elem):
        """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤—Å–µ–º–∏ –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏"""
        
        possible_comment_selectors = [
            '.tgme_widget_message_comments',
            '.tgme_widget_message_comment',
            '[class*="comment"]',
            '[class*="discussion"]',
            '[href*="comment"]',
            'span[title*="üí¨"]',
            'a[href*="/c/"]',  # –°—Å—ã–ª–∫–∏ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            '.message_comments',
            '.post_comments'
        ]
        
        for selector in possible_comment_selectors:
            elements = post_elem.select(selector)
            for elem in elements:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º href –¥–ª—è —Å—Å—ã–ª–æ–∫ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                href = elem.get('href', '')
                if href and '/c/' in href:
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑ href –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞
                    text = elem.get_text(strip=True)
                    if text and re.search(r'\d', text):
                        return self.convert_count_to_number(text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
                text = elem.get_text(strip=True)
                if text and re.search(r'\d', text):
                    return self.convert_count_to_number(text)
        
        # Telegram –æ–±—ã—á–Ω–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        # –≤ –ø—É–±–ª–∏—á–Ω–æ–º –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        return 0
    
    def try_extract_reposts(self, post_elem):
        """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å —Ä–µ–ø–æ—Å—Ç—ã/–ø–µ—Ä–µ—Å—ã–ª–∫–∏"""
        
        possible_repost_selectors = [
            '.tgme_widget_message_forwards',
            '.tgme_widget_message_forward',
            '[class*="forward"]',
            '[class*="share"]',
            '[class*="repost"]',
            'span[title*="üîÑ"]',
            '.message_forwards',
            '.post_shares'
        ]
        
        for selector in possible_repost_selectors:
            elements = post_elem.select(selector)
            for elem in elements:
                text = elem.get_text(strip=True)
                if text and re.search(r'\d', text):
                    return self.convert_count_to_number(text)
        
        return 0
    
    def convert_count_to_number(self, count_str):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É —Å—á–µ—Ç—á–∏–∫–∞ –≤ —á–∏—Å–ª–æ"""
        
        if not count_str or count_str == "N/A":
            return 0
        
        count_str = str(count_str).replace(' ', '').replace(',', '').lower()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ —Å—Ç—Ä–æ–∫–∏
        match = re.search(r'([\d.,]+[km]?)', count_str)
        if not match:
            return 0
        
        number_str = match.group(1)
        
        try:
            if 'k' in number_str:
                number = float(number_str.replace('k', ''))
                return int(number * 1000)
            elif 'm' in number_str:
                number = float(number_str.replace('m', ''))
                return int(number * 1000000)
            else:
                return int(float(number_str))
        except:
            return 0
    
    def analyze_metrics_availability(self, posts_data):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫"""
        
        if not posts_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        total_posts = len(posts_data)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
        has_views = sum(1 for p in posts_data if p['views'] > 0)
        has_likes = sum(1 for p in posts_data if p['likes'] > 0)
        has_comments = sum(1 for p in posts_data if p['comments'] > 0)
        has_reposts = sum(1 for p in posts_data if p['reposts'] > 0)
        
        print(f"\nüìä –î–û–°–¢–£–ü–ù–û–°–¢–¨ –ú–ï–¢–†–ò–ö (–∏–∑ {total_posts} –ø–æ—Å—Ç–æ–≤):")
        print(f"   üëÄ –ü—Ä–æ—Å–º–æ—Ç—Ä—ã: {has_views}/{total_posts} ({has_views/total_posts*100:.1f}%) ‚úÖ")
        print(f"   ‚ù§Ô∏è –õ–∞–π–∫–∏: {has_likes}/{total_posts} ({has_likes/total_posts*100:.1f}%)")
        print(f"   üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: {has_comments}/{total_posts} ({has_comments/total_posts*100:.1f}%)")
        print(f"   üîÑ –†–µ–ø–æ—Å—Ç—ã: {has_reposts}/{total_posts} ({has_reposts/total_posts*100:.1f}%)")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø 5 –ø–æ—Å—Ç–æ–≤ –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º
        print(f"\nüèÜ –¢–û–ü-5 –ü–û–°–¢–û–í –ü–û –ü–†–û–°–ú–û–¢–†–ê–ú:")
        top_posts = sorted(posts_data, key=lambda x: x['views'], reverse=True)[:5]
        
        for i, post in enumerate(top_posts, 1):
            engagement_info = ""
            if post['likes'] > 0 or post['comments'] > 0:
                engagement_info = f" | ‚ù§Ô∏è {post['likes']} üí¨ {post['comments']}"
            
            print(f"   {i}. üëÄ {post['views']:,}{engagement_info}")
            print(f"      üìù {post['text_preview'][:50]}...")
            print(f"      üîó {post['url']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        with open("telegram_enhanced_metrics.json", "w", encoding="utf-8") as f:
            json.dump(posts_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ telegram_enhanced_metrics.json")
        
        return {
            'total_posts': total_posts,
            'views_available': has_views,
            'likes_available': has_likes,
            'comments_available': has_comments,
            'reposts_available': has_reposts,
            'top_posts': top_posts
        }
    
    def get_full_analytics(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –∫–∞–Ω–∞–ª–∞"""
        
        print(f"üöÄ –ü–û–õ–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê @{self.channel}")
        print("=" * 80)
        
        # 1. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–Ω–∞–ª–µ
        channel_info = self.get_channel_info_bot_api()
        print(f"üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ö–ê–ù–ê–õ–ï:")
        if 'error' not in channel_info:
            print(f"   üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {channel_info['title']}")
            print(f"   üë• –ü–æ–¥–ø–∏—Å—á–∏–∫–∏: {channel_info['subscribers']:,}")
            print(f"   üÜî ID: {channel_info['id']}")
        else:
            print(f"   ‚ùå {channel_info['error']}")
        
        # 2. –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å—Ç–æ–≤
        posts_data = self.extract_posts_with_all_metrics()
        
        return {
            'channel_info': channel_info,
            'posts_data': posts_data,
            'summary': {
                'total_posts': len(posts_data),
                'total_views': sum(p['views'] for p in posts_data),
                'total_likes': sum(p['likes'] for p in posts_data),
                'total_comments': sum(p['comments'] for p in posts_data),
                'avg_views': sum(p['views'] for p in posts_data) / len(posts_data) if posts_data else 0
            }
        }

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    scraper = TelegramEnhancedScraper("rawmid")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É
    full_data = scraper.get_full_analytics()
    
    print(f"\n‚úÖ –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    summary = full_data['summary']
    print(f"   üìù –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {summary['total_posts']}")
    print(f"   üëÄ –í—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {summary['total_views']:,}")
    print(f"   üìä –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã: {summary['avg_views']:,.0f}")
    
    if summary['total_likes'] > 0:
        print(f"   ‚ù§Ô∏è –í—Å–µ–≥–æ –ª–∞–π–∫–æ–≤: {summary['total_likes']:,}")
    
    if summary['total_comments'] > 0:
        print(f"   üí¨ –í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {summary['total_comments']:,}")

if __name__ == "__main__":
    main() 