import httpx
import os
import base64
from dotenv import load_dotenv

class OpenRouterClient:
    """
    A client for interacting with the OpenRouter API, specifically for
    multimodal models that can analyze images.
    """
    def __init__(self):
        load_dotenv()
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY environment variable not set.")
        
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
        self.client = httpx.AsyncClient(timeout=60.0)
        
        # Using a capable, cheap model for this task.
        # Other options: "anthropic/claude-3-haiku", "google/gemini-flash-1.5"
        self.model = "anthropic/claude-3.5-sonnet"

    @staticmethod
    def encode_image_to_base64(image_path: str) -> str:
        """Encodes an image file to a base64 string."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            print(f"Error encoding image: {e}")
            return ""

    async def get_visual_critique_and_code(self, image_path: str, prompt: str, code_that_produced_image: str) -> dict:
        """
        Sends an image and a prompt to the multimodal LLM and gets a critique
        and new code in return.

        Returns:
            A dictionary with 'critique' and 'new_code' keys.
        """
        base64_image = self.encode_image_to_base64(image_path)
        if not base64_image:
            return {"critique": "Error encoding image.", "new_code": ""}

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        system_prompt = "You are an expert Blender Python (bpy) scripter. Your task is to analyze an image of a 3D model that was generated by a script, critique the result based on the user's prompt, and then provide a new, complete, and corrected Python script to better match the user's request. Only return the python code block, nothing else."
        
        full_prompt = f"""
The user's high-level goal is: '{prompt}'

The following Python script was used to generate the attached image:
```python
{code_that_produced_image}
```

Critique the resulting image attached below. Is it correct according to the user's goal? If not, what is wrong with the shape, and why did the code produce this flawed result?

After your critique, provide a single, complete, and corrected Python script for Blender that fixes these issues. The script should be runnable in one go. Do not include any explanation, just the raw Python code inside a ```python ... ``` block.
"""

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64_image}"
                            }
                        },
                        {
                            "type": "text",
                            "text": full_prompt
                        }
                    ]
                }
            ]
        }
        
        try:
            response = await self.client.post(self.api_url, headers=headers, json=payload)
            response.raise_for_status()
            response_data = response.json()
            
            content = response_data['choices'][0]['message']['content']
            
            # This is a simple parser. A more robust one would use regex.
            code_start = content.find("```python")
            code_end = content.rfind("```")

            if code_start != -1 and code_end != -1:
                new_code = content[code_start + len("```python"):code_end].strip()
                critique = content[:code_start].strip()
            else:
                new_code = content # Assume the whole response is code if no block is found
                critique = "Could not extract critique from LLM response."

            return {"critique": critique, "new_code": new_code}
            
        except httpx.RequestError as e:
            return {"critique": f"API request failed: {e}", "new_code": ""}
        except Exception as e:
            return {"critique": f"An unexpected error occurred: {e}", "new_code": ""} 