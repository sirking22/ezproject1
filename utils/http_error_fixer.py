#!/usr/bin/env python3
"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è HTTP –∑–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç try-catch –±–ª–æ–∫–∏ –∫ requests.get/post
"""

import re
import os
from typing import List, Tuple

def find_unsafe_requests(file_path: str) -> List[Tuple[int, str]]:
    """–ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã –≤ —Ñ–∞–π–ª–µ"""
    unsafe_patterns = [
        r'response\s*=\s*requests\.get\([^)]*\)',
        r'response\s*=\s*requests\.post\([^)]*\)',
        r'response\s*=\s*requests\.put\([^)]*\)',
        r'response\s*=\s*requests\.delete\([^)]*\)'
    ]
    
    unsafe_lines = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        
    for i, line in enumerate(lines, 1):
        for pattern in unsafe_patterns:
            if re.search(pattern, line.strip()):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ try-catch
                if not _has_try_catch_context(lines, i-1):
                    unsafe_lines.append((i, line.strip()))
                break
    
    return unsafe_lines

def _has_try_catch_context(lines: List[str], line_index: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ try-catch –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —Å—Ç—Ä–æ–∫–∏"""
    # –ò—â–µ–º try –≤—ã—à–µ
    try_found = False
    for i in range(line_index, -1, -1):
        if 'try:' in lines[i]:
            try_found = True
            break
        elif lines[i].strip() and not lines[i].strip().startswith('#'):
            break
    
    if not try_found:
        return False
    
    # –ò—â–µ–º except –Ω–∏–∂–µ
    for i in range(line_index, len(lines)):
        if 'except' in lines[i]:
            return True
        elif lines[i].strip() and not lines[i].strip().startswith('#'):
            break
    
    return False

def generate_safe_request_code(original_line: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–¥ –¥–ª—è HTTP –∑–∞–ø—Ä–æ—Å–∞"""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
    match = re.search(r'requests\.(\w+)\(([^)]*)\)', original_line)
    if not match:
        return original_line
    
    method = match.group(1)
    params = match.group(2)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è response
    var_match = re.search(r'(\w+)\s*=\s*requests\.', original_line)
    var_name = var_match.group(1) if var_match else 'response'
    
    safe_code = f"""try:
    {var_name} = requests.{method}({params})
    {var_name}.raise_for_status()
    return {var_name}.json()
except requests.RequestException as e:
    logger.error(f"Error in {method.upper()} request: {{e}}")
    raise"""
    
    return safe_code

def fix_file(file_path: str) -> bool:
    """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª, –¥–æ–±–∞–≤–ª—è—è –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫"""
    print(f"üîß –ò—Å–ø—Ä–∞–≤–ª—è—é {file_path}...")
    
    unsafe_lines = find_unsafe_requests(file_path)
    if not unsafe_lines:
        print(f"‚úÖ {file_path} - –±–µ–∑–æ–ø–∞—Å–µ–Ω")
        return True
    
    print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(unsafe_lines)} –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
    for line_num, line in unsafe_lines:
        print(f"   –°—Ç—Ä–æ–∫–∞ {line_num}: {line}")
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if 'import requests' in content and 'logger' not in content:
        content = content.replace(
            'import requests',
            'import requests\nimport logging\n\nlogger = logging.getLogger(__name__)'
        )
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
    print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è {file_path}:")
    for line_num, line in unsafe_lines[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
        safe_code = generate_safe_request_code(line)
        print(f"\n–°—Ç—Ä–æ–∫–∞ {line_num}:")
        print(f"‚ùå {line}")
        print(f"‚úÖ {safe_code}")
    
    return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üö® –ü–†–û–í–ï–†–ö–ê HTTP –ó–ê–ü–†–û–°–û–í –ù–ê –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨")
    print("=" * 50)
    
    # –§–∞–π–ª—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    files_to_check = [
        'universal_social_metrics.py',
        'telegram_analytics_framework.py',
        'setup_templates_chain.py',
        'setup_kpi_relations.py',
        'setup_business_chains.py',
        'optimize_existing_kpi.py',
        'notion_universal_fields.py',
        'notion_fields_setup.py',
        'link_guides_to_templates.py',
        'kpi_migration_full.py',
        'kpi_simple_migration.py',
        'fix_kpi_relations.py',
        'fix_kpi_api.py',
        'dual_level_analytics.py',
        'daily_telegram_monitor.py'
    ]
    
    unsafe_files = []
    
    for file_path in files_to_check:
        if os.path.exists(file_path):
            if not fix_file(file_path):
                unsafe_files.append(file_path)
        else:
            print(f"‚ö†Ô∏è  –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    print("\n" + "=" * 50)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–í–ï–†–ö–ò:")
    print(f"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(files_to_check) - len(unsafe_files)}")
    print(f"‚ùå –§–∞–π–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏: {len(unsafe_files)}")
    
    if unsafe_files:
        print(f"\nüö® –§–ê–ô–õ–´ –¢–†–ï–ë–£–Æ–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:")
        for file_path in unsafe_files:
            print(f"   ‚Ä¢ {file_path}")
        
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("   1. –î–æ–±–∞–≤–∏—Ç—å try-catch –±–ª–æ–∫–∏ –∫ HTTP –∑–∞–ø—Ä–æ—Å–∞–º")
        print("   2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å response.raise_for_status()")
        print("   3. –î–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫")
        print("   4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É—Ç–∏–ª–∏—Ç—É utils/console_helpers.safe_request()")

if __name__ == "__main__":
    main() 