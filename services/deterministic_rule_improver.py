"""
–°–∏—Å—Ç–µ–º–∞ —É–ª—É—á—à–µ–Ω–∏—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import json
import re
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import asyncio

@dataclass
class RuleImprovement:
    """–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞"""
    rule_name: str
    old_pattern: str
    new_pattern: str
    reason: str
    confidence: float
    test_cases: List[str]

@dataclass
class PerformanceMetric:
    """–ú–µ—Ç—Ä–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª–∞"""
    rule_name: str
    success_rate: float
    average_time_ms: float
    error_patterns: List[Dict[str, str]]
    improvement_suggestions: List[str]

class DeterministicRuleImprover:
    """–°–∏—Å—Ç–µ–º–∞ —É–ª—É—á—à–µ–Ω–∏—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª"""
    
    def __init__(self):
        self.improvements = []
        self.performance_metrics = []
        self.test_results = {"results": []}
        self.current_rules = {
            "title_cleaning": {
                "patterns": [
                    (r'^üì±\s*', ''),
                    (r'^https://.*?\s', ''),
                    (r'\s+', ' '),
                    (r'^\s+|\s+$', '')
                ],
                "description": "–û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –æ—Ç —ç–º–æ–¥–∑–∏, —Å—Å—ã–ª–æ–∫ –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"
            },
            "auto_tagging": {
                "domains": {
                    "instagram.com": "Social Media",
                    "youtube.com": "Video Platform",
                    "facebook.com": "Social Media",
                    "vk.com": "Social Media",
                    "t.me": "Telegram"
                },
                "keywords": {
                    "–¥–∏–∑–∞–π–Ω": "Design",
                    "design": "Design",
                    "figma": "Design",
                    "ui": "Design",
                    "ux": "Design",
                    "–≤–∏–¥–µ–æ": "Video",
                    "video": "Video",
                    "youtube": "Video",
                    "–º–æ–Ω—Ç–∞–∂": "Video",
                    "—Ñ–æ—Ç–æ": "Photo",
                    "photo": "Photo",
                    "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ": "Photo",
                    "image": "Photo"
                },
                "description": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –¥–æ–º–µ–Ω–∞–º –∏ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"
            },
            "classification": {
                "rules": [
                    ("len(text) < 3", "Garbage"),
                    ("len(text) > 100", "Long Content"),
                    ("contains_digits", "Data Entry"),
                    ("contains_emoji", "Social Content"),
                    ("starts_with_http", "Link"),
                    ("default", "Regular Content")
                ],
                "description": "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ —Ç–∏–ø—É"
            }
        }
    
    def load_test_results(self, filename: str = "deterministic_test_results.json"):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.test_results = data
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data.get('results', []))} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            self.test_results = {"results": []}
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            self.test_results = {"results": []}
    
    def analyze_performance(self) -> List[PerformanceMetric]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª"""
        if not self.test_results.get("results"):
            print("‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º
        rule_results = {}
        for result in self.test_results["results"]:
            rule_name = result["rule_name"]
            if rule_name not in rule_results:
                rule_results[rule_name] = []
            rule_results[rule_name].append(result)
        
        metrics = []
        
        for rule_name, results in rule_results.items():
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            total_tests = len(results)
            successful_tests = len([r for r in results if r["success"]])
            success_rate = successful_tests / total_tests if total_tests > 0 else 0
            
            # –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è
            times = [r["processing_time_ms"] for r in results if r["success"]]
            average_time = sum(times) / len(times) if times else 0
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
            errors = [r for r in results if not r["success"]]
            error_patterns = []
            for error in errors:
                error_patterns.append({
                    "input": error["input_text"][:50],
                    "error": error.get("error_message", "Unknown error")
                })
            
            # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
            improvements = self.generate_improvement_suggestions(rule_name, results)
            
            metric = PerformanceMetric(
                rule_name=rule_name,
                success_rate=success_rate,
                average_time_ms=average_time,
                error_patterns=error_patterns,
                improvement_suggestions=improvements
            )
            
            metrics.append(metric)
        
        self.performance_metrics = metrics
        return metrics
    
    def generate_improvement_suggestions(self, rule_name: str, results: List[Dict]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–∞–≤–∏–ª"""
        suggestions = []
        
        if rule_name == "title_cleaning":
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª—É—á–∞–∏, –≥–¥–µ –æ—á–∏—Å—Ç–∫–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞
            failed_results = [r for r in results if not r["success"]]
            if failed_results:
                suggestions.append("–î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤")
                suggestions.append("–£–ª—É—á—à–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Å—Å—ã–ª–æ–∫")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            long_titles = [r for r in results if len(r["input_text"]) > 50]
            if long_titles:
                suggestions.append("–î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–µ–∑–∫—É –¥–ª–∏–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π")
        
        elif rule_name == "auto_tagging":
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª—É—á–∞–∏ –±–µ–∑ —Ç–µ–≥–æ–≤
            no_tags = []
            for r in results:
                if r["success"] and isinstance(r["output"], dict):
                    tags = r["output"].get("tags", [])
                    if not tags:
                        no_tags.append(r["input_text"])
            
            if no_tags:
                suggestions.append("–†–∞—Å—à–∏—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
                suggestions.append("–î–æ–±–∞–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–º–µ–Ω—ã
            domains_in_text = []
            for result in results:
                text = result["input_text"].lower()
                if any(domain in text for domain in ["instagram", "youtube", "facebook", "vk"]):
                    domains_in_text.append(result["input_text"])
            
            if domains_in_text:
                suggestions.append("–£–ª—É—á—à–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –¥–æ–º–µ–Ω–æ–≤")
        
        elif rule_name == "classification":
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
            misclassified = []
            for result in results:
                if result["success"]:
                    output = result["output"]
                    if isinstance(output, dict) and "category" in output:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                        text = result["input_text"]
                        expected_category = self.classify_content_improved(text)
                        actual_category = output["category"]
                        
                        if expected_category != actual_category:
                            misclassified.append({
                                "text": text,
                                "expected": expected_category,
                                "actual": actual_category
                            })
            
            if misclassified:
                suggestions.append("–£–ª—É—á—à–∏—Ç—å –ª–æ–≥–∏–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
                suggestions.append("–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")
        
        return suggestions
    
    def classify_content_improved(self, text: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        cleaned = text.strip()
        
        # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –ª–æ–≥–∏–∫–∞
        if len(cleaned) < 3:
            return "Garbage"
        elif len(cleaned) > 100:
            return "Long Content"
        elif any(char.isdigit() for char in cleaned):
            return "Data Entry"
        elif any(ord(char) > 127 for char in cleaned):
            return "Social Content"
        elif cleaned.startswith("http"):
            return "Link"
        elif any(word in cleaned.lower() for word in ["–¥–∏–∑–∞–π–Ω", "design", "figma"]):
            return "Design Content"
        elif any(word in cleaned.lower() for word in ["–≤–∏–¥–µ–æ", "video", "youtube"]):
            return "Video Content"
        else:
            return "Regular Content"
    
    def create_rule_improvements(self) -> List[RuleImprovement]:
        """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        improvements = []
        
        for metric in self.performance_metrics:
            if metric.success_rate < 0.9:  # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –º–µ–Ω—å—à–µ 90%
                
                if metric.rule_name == "title_cleaning":
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—á–∏—Å—Ç–∫–∏
                    improvement = RuleImprovement(
                        rule_name="title_cleaning",
                        old_pattern="basic_cleaning",
                        new_pattern="enhanced_cleaning",
                        reason=f"–ù–∏–∑–∫–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {metric.success_rate:.1%}",
                        confidence=0.8,
                        test_cases=[error["input"] for error in metric.error_patterns[:3]]
                    )
                    improvements.append(improvement)
                
                elif metric.rule_name == "auto_tagging":
                    # –†–∞—Å—à–∏—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤
                    improvement = RuleImprovement(
                        rule_name="auto_tagging",
                        old_pattern="basic_tagging",
                        new_pattern="enhanced_tagging",
                        reason=f"–ù–∏–∑–∫–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {metric.success_rate:.1%}",
                        confidence=0.7,
                        test_cases=[error["input"] for error in metric.error_patterns[:3]]
                    )
                    improvements.append(improvement)
                
                elif metric.rule_name == "classification":
                    # –£–ª—É—á—à–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
                    improvement = RuleImprovement(
                        rule_name="classification",
                        old_pattern="basic_classification",
                        new_pattern="enhanced_classification",
                        reason=f"–ù–∏–∑–∫–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {metric.success_rate:.1%}",
                        confidence=0.9,
                        test_cases=[error["input"] for error in metric.error_patterns[:3]]
                    )
                    improvements.append(improvement)
        
        self.improvements = improvements
        return improvements
    
    def apply_improvements(self) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –∫ –ø—Ä–∞–≤–∏–ª–∞–º"""
        improved_rules = self.current_rules.copy()
        
        for improvement in self.improvements:
            if improvement.rule_name == "title_cleaning":
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—á–∏—Å—Ç–∫–∏
                improved_rules["title_cleaning"]["patterns"].extend([
                    (r'[^\w\s\-\.]', ''),  # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                    (r'\s{2,}', ' '),      # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
                    (r'^\d+\s*', ''),      # –¶–∏—Ñ—Ä—ã –≤ –Ω–∞—á–∞–ª–µ
                ])
            
            elif improvement.rule_name == "auto_tagging":
                # –†–∞—Å—à–∏—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                improved_rules["auto_tagging"]["domains"].update({
                    "tiktok.com": "Social Media",
                    "twitter.com": "Social Media",
                    "linkedin.com": "Professional",
                    "medium.com": "Content"
                })
                
                improved_rules["auto_tagging"]["keywords"].update({
                    "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥": "Marketing",
                    "marketing": "Marketing",
                    "—Ä–µ–∫–ª–∞–º–∞": "Advertising",
                    "advertising": "Advertising",
                    "–∫–æ–Ω—Ç–µ–Ω—Ç": "Content",
                    "content": "Content"
                })
            
            elif improvement.rule_name == "classification":
                # –£–ª—É—á—à–∞–µ–º –ª–æ–≥–∏–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                improved_rules["classification"]["rules"] = [
                    ("len(text) < 3", "Garbage"),
                    ("len(text) > 100", "Long Content"),
                    ("contains_digits", "Data Entry"),
                    ("contains_emoji", "Social Content"),
                    ("starts_with_http", "Link"),
                    ("contains_design_keywords", "Design Content"),
                    ("contains_video_keywords", "Video Content"),
                    ("contains_marketing_keywords", "Marketing Content"),
                    ("default", "Regular Content")
                ]
        
        return improved_rules
    
    def save_improvements(self, filename: str = "rule_improvements.json"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª"""
        data = {
            "timestamp": datetime.now().isoformat(),
            "performance_metrics": [
                {
                    "rule_name": m.rule_name,
                    "success_rate": m.success_rate,
                    "average_time_ms": m.average_time_ms,
                    "error_patterns": m.error_patterns,
                    "improvement_suggestions": m.improvement_suggestions
                }
                for m in self.performance_metrics
            ],
            "improvements": [
                {
                    "rule_name": i.rule_name,
                    "old_pattern": i.old_pattern,
                    "new_pattern": i.new_pattern,
                    "reason": i.reason,
                    "confidence": i.confidence,
                    "test_cases": i.test_cases
                }
                for i in self.improvements
            ],
            "improved_rules": self.apply_improvements()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –£–ª—É—á—à–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
    
    def print_analysis_summary(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–∫—É –∞–Ω–∞–ª–∏–∑–∞"""
        if not self.performance_metrics:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        print("\nüìä –ê–ù–ê–õ–ò–ó –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò –î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–´–• –ü–†–ê–í–ò–õ")
        print("=" * 60)
        
        for metric in self.performance_metrics:
            print(f"\nüîß {metric.rule_name.upper()}:")
            print(f"   –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {metric.success_rate:.1%}")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {metric.average_time_ms:.2f}ms")
            
            if metric.improvement_suggestions:
                print(f"   –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:")
                for suggestion in metric.improvement_suggestions:
                    print(f"     ‚Ä¢ {suggestion}")
        
        print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        total_rules = len(self.performance_metrics)
        high_performance = len([m for m in self.performance_metrics if m.success_rate > 0.9])
        low_performance = len([m for m in self.performance_metrics if m.success_rate < 0.7])
        
        print(f"   –í—Å–µ–≥–æ –ø—Ä–∞–≤–∏–ª: {total_rules}")
        print(f"   –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {high_performance}")
        print(f"   –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è: {low_performance}")
        
        if self.improvements:
            print(f"\nüöÄ –ü–†–ï–î–õ–û–ñ–ï–ù–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
            for improvement in self.improvements:
                print(f"   ‚Ä¢ {improvement.rule_name}: {improvement.reason}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª"""
    
    improver = DeterministicRuleImprover()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    improver.load_test_results()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    metrics = improver.analyze_performance()
    
    # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–∏—è
    improvements = improver.create_rule_improvements()
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
    improver.print_analysis_summary()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–∏—è
    improver.save_improvements()
    
    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")

if __name__ == "__main__":
    main() 