#!/usr/bin/env python3
"""
üîó Webhook –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è Notion —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ–±–ª–æ–∂–µ–∫ –∏ Files & media
–§–ò–ù–ê–õ–¨–ù–ê–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø - —Å–æ–±—Ä–∞–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ–ø—ã—Ç–∞.
"""

import json
import os
import re
from urllib.parse import quote
import aiohttp
import asyncio
import traceback

# --- CONFIGURATION ---
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
FIGMA_TOKEN = os.getenv("FIGMA_TOKEN")
YANDEX_DISK_TOKEN = os.getenv("YANDEX_DISK_TOKEN")

# --- CONSTANTS ---
CLOUDFLARE_WORKER_URL = "https://delicate-hat-c01b.e1vice.workers.dev"
NOTION_API_VERSION = "2022-06-28"
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

# –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
DATABASES = {
    "materials": "1d9ace03-d9ff-8041-91a4-d35aeedcbbd4",
    "design_tasks": "d09df250-ce7e-4e0d-9fbe-4e036d320def", 
    "subtasks": "9c5f4269-d614-49b6-a748-5579a3c21da3",
    "projects": "342f18c6-7a5e-41fe-ad73-dcec00770f4e",
    "ideas": "ad92a6e2-1485-428c-84de-8587706b3be1"
}

def log(message):
    """–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
    print(f"[HANDLER] {message}")

def get_base_headers():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Notion —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏."""
    return {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_API_VERSION,
        "User-Agent": USER_AGENT,
    }

def get_base_headers_with_content_type():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å Content-Type –¥–ª—è POST/PATCH –∑–∞–ø—Ä–æ—Å–æ–≤."""
    return {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_API_VERSION,
        "User-Agent": USER_AGENT,
    }

async def get_notion_page(session, page_id):
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Notion —á–µ—Ä–µ–∑ Cloudflare Worker."""
    url = f"{CLOUDFLARE_WORKER_URL}/v1/pages/{page_id}"
    headers = get_base_headers()
    
    log(f"üîç [get_notion_page] –ó–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {page_id}")
    log(f"üîë –¢–æ–∫–µ–Ω: {NOTION_TOKEN[:10] if NOTION_TOKEN else 'None'}...")
    log(f"üîë –ü–æ–ª–Ω—ã–π —Ç–æ–∫–µ–Ω: {NOTION_TOKEN}")
    log(f"üîë –î–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–∞: {len(NOTION_TOKEN) if NOTION_TOKEN else 0}")
    log(f"üéØ URL —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏: {url}")
    
    async with session.get(url, headers=headers) as response:
        log(f"‚úÖ [get_notion_page] –û—Ç–≤–µ—Ç –æ—Ç –ø—Ä–æ–∫—Å–∏: {response.status}")
        if response.status == 200:
            return await response.json()
        
        error_text = await response.text()
        log(f"‚ùå [get_notion_page] –û—à–∏–±–∫–∞: {response.status} - {error_text}")
        return None

async def update_notion_cover(session, page_id, cover_url):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ–±–ª–æ–∂–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã Notion."""
    url = f"{CLOUDFLARE_WORKER_URL}/v1/pages/{page_id}"
    data = {"cover": {"type": "external", "external": {"url": cover_url}}}
    headers = get_base_headers_with_content_type()
    
    log(f"üñºÔ∏è [update_notion_cover] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±–ª–æ–∂–∫–∏ –¥–ª—è {page_id}...")
    async with session.patch(url, json=data, headers=headers) as response:
        success = response.status == 200
        log(f"üñºÔ∏è [update_notion_cover] –†–µ–∑—É–ª—å—Ç–∞—Ç: {'‚úÖ' if success else '‚ùå'}")
        if not success:
            log(f"‚ùå [update_notion_cover] –û—à–∏–±–∫–∞: {await response.text()}")
        return success

async def update_notion_files_media(session, page_id, file_url):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–≤–æ–π—Å—Ç–≤–æ 'Files & media' —Å—Ç—Ä–∞–Ω–∏—Ü—ã Notion."""
    url = f"{CLOUDFLARE_WORKER_URL}/v1/pages/{page_id}"
    data = {
        "properties": {
            "Files & media": {
                "files": [{"name": "Material File", "type": "external", "external": {"url": file_url}}]
            }
        }
    }
    headers = get_base_headers_with_content_type()

    log(f"üìé [update_notion_files_media] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Files & media –¥–ª—è {page_id}...")
    async with session.patch(url, json=data, headers=headers) as response:
        success = response.status == 200
        log(f"üìé [update_notion_files_media] –†–µ–∑—É–ª—å—Ç–∞—Ç: {'‚úÖ' if success else '‚ùå'}")
        if not success:
            log(f"‚ùå [update_notion_files_media] –û—à–∏–±–∫–∞: {await response.text()}")
        return success

async def get_figma_cover(session, figma_url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –ø—Ä–µ–≤—å—é –∏–∑ —Å—Å—ã–ª–∫–∏ Figma."""
    # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ file_key
    file_key_match = re.search(r"(?:file|design)/([a-zA-Z0-9]+)", figma_url)
    if not file_key_match: return None
    file_key = file_key_match.group(1)

    # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ node_id
    node_id_match = re.search(r"node-id=([a-zA-Z0-9%:-]+)", figma_url)
    if not node_id_match: return None
    node_id = quote(node_id_match.group(1).replace(':', '-')) # Figma API –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç '-'

    api_url = f"https://api.figma.com/v1/images/{file_key}?ids={node_id}&format=png&scale=2"
    headers = {"X-Figma-Token": FIGMA_TOKEN}
    
    async with session.get(api_url, headers=headers) as response:
        if response.status != 200:
             log(f"‚ùå [get_figma_cover] –û—à–∏–±–∫–∞ API Figma: {response.status} - {await response.text()}")
             return None
        data = await response.json()
        if data.get('err'):
            log(f"‚ùå [get_figma_cover] –û—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ Figma: {data['err']}")
            return None
        
        image_url = data.get('images', {}).get(node_id.replace('%3A', ':')) # API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ':' –≤ ID
        if not image_url:
             image_url = data.get('images', {}).get(node_id)
        
        return image_url

async def get_lightshot_image(session, lightshot_url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Å—Å—ã–ª–∫–∏ LightShot (–†–ê–ë–û–ß–ê–Ø –í–ï–†–°–ò–Ø)."""
    try:
        log(f"üîç [get_lightshot_image] –ó–∞–ø—Ä–∞—à–∏–≤–∞—é LightShot: {lightshot_url}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }
        
        async with session.get(lightshot_url, headers=headers, timeout=aiohttp.ClientTimeout(total=30)) as response:
            log(f"üìä [get_lightshot_image] –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status}")
            if response.status != 200:
                log(f"‚ùå [get_lightshot_image] –û—à–∏–±–∫–∞ HTTP: {response.status}")
                return None
            
            html = await response.text()
            log(f"üìÑ [get_lightshot_image] –†–∞–∑–º–µ—Ä HTML: {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ò—â–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–π –≤–µ—Ä—Å–∏–∏)
            image_patterns = [
                r'https://image\.prntscr\.com/image/[^"\']+',
                r'https://[^"\']*\.png',
                r'https://[^"\']*\.jpg',
                r'https://[^"\']*\.jpeg',
                r'https://[^"\']*\.webp'
            ]
            
            for pattern in image_patterns:
                matches = re.findall(pattern, html)
                if matches:
                    image_url = matches[0]
                    log(f"‚úÖ [get_lightshot_image] –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ LightShot: {image_url}")
                    return image_url
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –º–µ—Ç–∞-—Ç–µ–≥–æ–≤
            meta_pattern = r'<meta property="og:image" content="([^"]+)"'
            meta_matches = re.findall(meta_pattern, html)
            if meta_matches:
                image_url = meta_matches[0]
                log(f"‚úÖ [get_lightshot_image] –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ meta: {image_url}")
                return image_url
            
            log(f"‚ö†Ô∏è [get_lightshot_image] –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ HTML")
            return None
            
    except Exception as e:
        log(f"‚ùå [get_lightshot_image] –û—à–∏–±–∫–∞: {e}")
        return None

async def get_yandex_disk_image(session, yandex_url):
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞."""
    # –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –¥–ª—è –ø—Ä–µ–≤—å—é –Ω–µ —Ç—Ä–µ–±—É–µ—Ç API —Ç–æ–∫–µ–Ω–∞
    public_key = quote(yandex_url)
    api_url = f"https://cloud-api.yandex.net/v1/disk/public/resources?public_key={public_key}"
    async with session.get(api_url) as response:
        if response.status != 200:
            log(f"‚ùå [get_yandex_disk_image] –û—à–∏–±–∫–∞ API –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞: {response.status}")
            return None
        data = await response.json()
        return data.get("preview") # –í–æ–∑–≤—Ä–∞—â–∞–µ–º URL –ø—Ä–µ–≤—å—é

async def get_cover_url_from_link(session, link):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Å—Å—ã–ª–∫–∏ –∏ –≤—ã–∑—ã–≤–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫."""
    if "figma.com" in link:
        log(f"üé® –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é Figma: {link}")
        return await get_figma_cover(session, link)
    if "prnt.sc" in link or "lightshot.cc" in link:
        log(f"üì∏ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é LightShot: {link}")
        return await get_lightshot_image(session, link)
    if "disk.yandex.ru" in link:
        log(f"‚òÅÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫: {link}")
        return await get_yandex_disk_image(session, link)
    if any(ext in link.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']):
        log(f"üñºÔ∏è –ü—Ä—è–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {link}")
        return link
    log(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å—Å—ã–ª–∫–∏: {link}")
    return None

async def process_page_update(session, page_id, page_data):
    """–û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""
    log(f"üîÑ [process_page_update] –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_id}")
    properties = page_data.get("properties", {})
    
    url_property = None
    for prop_name in ["URL", "Link", "–°—Å—ã–ª–∫–∞", "url", "link"]:
        if prop_name in properties:
            prop = properties[prop_name]
            if prop.get("type") == "url" and prop.get("url"):
                url_property = prop["url"]
                log(f"üîó [process_page_update] –ù–∞–π–¥–µ–Ω URL: {url_property}")
                break
    
    if not url_property:
        log("‚ö†Ô∏è [process_page_update] URL –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–≤–æ–π—Å—Ç–≤–∞—Ö.")
        return

    cover_url = await get_cover_url_from_link(session, url_property)
    if not cover_url:
        log("‚ö†Ô∏è [process_page_update] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å URL –æ–±–ª–æ–∂–∫–∏.")
        return

    log(f"‚úÖ [process_page_update] –û–±–ª–æ–∂–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞: {cover_url[:100]}...")
    await update_notion_cover(session, page_id, cover_url)
    
    parent_db_id = page_data.get("parent", {}).get("database_id", "").replace("-", "")
    if parent_db_id == DATABASES["materials"].replace("-", ""):
        log("üìé [process_page_update] –û–±–Ω–æ–≤–ª—è—é Files & media –¥–ª—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤...")
        await update_notion_files_media(session, page_id, cover_url)

async def handler_async(event, context):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤."""
    log("üöÄ –ü–û–õ–£–ß–ï–ù –ó–ê–ü–†–û–°")
    log(f"üîç –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: NOTION_TOKEN={'‚úÖ' if NOTION_TOKEN else '‚ùå'}, FIGMA_TOKEN={'‚úÖ' if FIGMA_TOKEN else '‚ùå'}, YANDEX_DISK_TOKEN={'‚úÖ' if YANDEX_DISK_TOKEN else '‚ùå'}")

    try:
        webhook_data = json.loads(event.get('body', '{}')) if isinstance(event.get('body'), str) else event.get('body', {})
        if not webhook_data:
            webhook_data = event # –ï—Å–ª–∏ body –ø—É—Å—Ç, –Ω–æ —Å–∞–º event - —ç—Ç–æ JSON
    except (json.JSONDecodeError, TypeError):
        log("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å JSON –∏–∑ body, –∏—Å–ø–æ–ª—å–∑—É–µ–º event –∫–∞–∫ –µ—Å—Ç—å.")
        webhook_data = event

    # –î–ª—è Notion webhooks, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Ö–æ–¥—è—Ç –±–µ–∑ 'body'
    if 'event' in webhook_data and 'page' in webhook_data:
         log("–û–±–Ω–∞—Ä—É–∂–µ–Ω —Ñ–æ—Ä–º–∞—Ç Notion webhook v2")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ challenge –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ URL –≤–µ–±—Ö—É–∫–∞
    if 'challenge' in webhook_data:
        challenge = webhook_data['challenge']
        log(f"‚úÖ URL verification challenge: {challenge}")
        return {"statusCode": 200, "body": json.dumps({"challenge": challenge})}
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ page_id –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
    page_id = None
    if 'page' in webhook_data and isinstance(webhook_data['page'], dict) and 'id' in webhook_data['page']:
        page_id = webhook_data['page']['id']
    elif 'entity' in webhook_data and 'id' in webhook_data['entity']: # Fallback
        page_id = webhook_data['entity']['id']

    if not page_id:
        log(f"‚ùå ID —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ webhook. –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {list(webhook_data.keys())}")
        return {'statusCode': 200, 'body': 'OK (page_id not found)'}

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º page_id –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π UUID —Ñ–æ—Ä–º–∞—Ç (–¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ñ–∏—Å—ã)
    log(f"üîß [handler_async] –ò—Å—Ö–æ–¥–Ω—ã–π page_id: {page_id} (–¥–ª–∏–Ω–∞: {len(page_id) if page_id else 0})")
    if page_id and len(page_id) == 32 and '-' not in page_id:  # UUID –±–µ–∑ –¥–µ—Ñ–∏—Å–æ–≤
        page_id = f"{page_id[:8]}-{page_id[8:12]}-{page_id[12:16]}-{page_id[16:20]}-{page_id[20:32]}"
        log(f"üîß [handler_async] –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω page_id: {page_id}")
    elif page_id and len(page_id) == 36 and page_id.count('-') == 4:  # UUID —Å –¥–µ—Ñ–∏—Å–∞–º–∏
        log(f"üîß [handler_async] page_id —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ: {page_id}")
    else:
        log(f"‚ö†Ô∏è [handler_async] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç page_id: {page_id}")
        # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –µ—Å—Ç—å, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç ID

    log(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É: {page_id}")
    
    async with aiohttp.ClientSession() as session:
        page_data = await get_notion_page(session, page_id)
        if not page_data:
            log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ó–∞–≤–µ—Ä—à–∞—é.")
            return {'statusCode': 200, 'body': 'OK (page data fetch failed)'}
        
        await process_page_update(session, page_id, page_data)
            
    return {'statusCode': 200, 'body': 'OK'}

def handler(event, context):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è Yandex Cloud Function."""
    try:
        return asyncio.run(handler_async(event, context))
    except Exception as e:
        log(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≤ handler: {e}")
        log(traceback.format_exc())
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 200, —á—Ç–æ–±—ã Notion –Ω–µ –æ—Ç–∫–ª—é—á–∏–ª –≤–µ–±—Ö—É–∫
        return {'statusCode': 200, 'body': f'Critical error: {e}'}
